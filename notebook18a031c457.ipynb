{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 8015943,
          "sourceType": "datasetVersion",
          "datasetId": 4707959
        }
      ],
      "dockerImageVersionId": 30684,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "notebook18a031c457",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/engrwaseemakhtar/Transfer-Learning-with-VGG16-for-Image-Recognition/blob/main/notebook18a031c457.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'smart-grid-phasor-measurement-unit-faulty-data:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F4707959%2F8015943%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240525%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240525T201229Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D443af30792c870fd4f56d0589a457d40a537dffc715befa001263cbee909d4e55a6423d1cfc6379bdd6c45ef352afc1bc5b2e4d65ac051ff776a7e3404b5f9512fc568840abdaacf3891a6eb16eba00fc4baacb8ca7a4527df572c591fafe97f02ae3ca0e1487949defb5e482a441cea2aa5f433ea7902ebe1fc11b65bd627454fc56563a1814a9d7410e48ba6785b1ec61f6d064fcd9b5b8e8d44fd41b38c7e0a22578fa9d6ca14fed76b1b3d594504d6856ef39c4359c9572e66512358db5d99eb15676ec94bdc5e3ff8d4661c8004aeb52d87f5950e0fdd3e5e62954f8c18d77fbd010dddf9e02d29b698fee3fbef88dc2708d1a80775e93ef4ca56c4899b'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "3ndutNW3ZlWl"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "<span class=\"label label-default\" style=\"background-color:#DC1010; border-radius:16px; font-weight: bold; font-family:Verdana; font-size:34px; color:#FBFAFC; \">VGG16: A Deep Convolutional Neural Network for Image Recognition.ðŸ“ŠðŸ“ˆ</span>\n",
        "    "
      ],
      "metadata": {
        "id": "8s9JWl6QZlWn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"Brown\" size=+2 face=\"Comic Sans MS\"><div style=\"text-align: justify\">VGG16, introduced in 2014, is a convolutional neural network (CNN) architecture that played a significant role in advancing the field of computer vision.</font>"
      ],
      "metadata": {
        "id": "V0YB4n8sZlWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://miro.medium.com/v2/resize:fit:827/1*UeAhoKM0kJfCPA03wt5H0A.png\" width=\"100%\" height=\"70%\" />"
      ],
      "metadata": {
        "id": "COknjMLpZlWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"color:white;\n",
        "           display:fill;\n",
        "           border-radius:5px;\n",
        "           background-color:#5642C5;\n",
        "           font-size:33px;\n",
        "           font-family:Nexa;\n",
        "           letter-spacing:0.5px\">\n",
        "        <p style=\"padding: 15px;\n",
        "              color:white;\">\n",
        "            <b>Importance of CNNs: VGG16</b>\n",
        "        </p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "T4HdMESMZlWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"Brown\" size=+2 face=\"Comic Sans MS\"><div style=\"text-align: justify\">Depth in CNNs: VGG16 demonstrated the effectiveness of deep convolutional architectures in achieving superior performance on image recognition tasks. Its success paved the way for exploring even deeper networks that pushed the boundaries of computer vision capabilities.</font>"
      ],
      "metadata": {
        "id": "yd-oBKTiZlWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"Brown\" size=+2 face=\"Comic Sans MS\"><div style=\"text-align: justify\">Standardization and Comparison: VGG16 became a popular baseline model for researchers and practitioners. It served as a reference point for comparing the performance of new architectures on image classification datasets like ImageNet.</font>"
      ],
      "metadata": {
        "id": "O63CKmzyZlWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"color:white;\n",
        "           display:fill;\n",
        "           border-radius:5px;\n",
        "           background-color:#5642C5;\n",
        "           font-size:33px;\n",
        "           font-family:Nexa;\n",
        "           letter-spacing:0.5px\">\n",
        "        <p style=\"padding: 15px;\n",
        "              color:white;\">\n",
        "            <b>Usages of CNNs: VGG16</b>\n",
        "        </p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "nb0PY662ZlWo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"Brown\" size=+2 face=\"Comic Sans MS\"><div style=\"text-align: justify\">Image Classification: VGG16 can be used to classify images into various categories, such as animals, objects, or scenes. It can be fine-tuned for specific classification tasks by modifying the final layers of the network and retraining it with labeled data.</font>"
      ],
      "metadata": {
        "id": "Tlr7EOpWZlWp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"Brown\" size=+2 face=\"Comic Sans MS\"><div style=\"text-align: justify\">Feature Extraction: Even the earlier layers of VGG16 learn valuable features from images. These features can be extracted and used as input to other machine learning models for tasks like object detection, image segmentation, or image retrieval.\n",
        "</font>"
      ],
      "metadata": {
        "id": "yC_rveNbZlWp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<div style=\"color:white;\n",
        "           display:fill;\n",
        "           border-radius:5px;\n",
        "           background-color:#5642C5;\n",
        "           font-size:33px;\n",
        "           font-family:Nexa;\n",
        "           letter-spacing:0.5px\">\n",
        "        <p style=\"padding: 15px;\n",
        "              color:white;\">\n",
        "            <b>Key Points of CNNs: VGG16</b>\n",
        "        </p>\n",
        "</div>"
      ],
      "metadata": {
        "id": "NMGtEwAIZlWp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"Brown\" size=+2 face=\"Comic Sans MS\"><div style=\"text-align: justify\">VGG16 relies on a series of convolutional layers with small filters (usually 3x3) stacked together. This approach allows the network to learn complex hierarchical features from images.</font>"
      ],
      "metadata": {
        "id": "cdDsv3rhZlWp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"Brown\" size=+2 face=\"Comic Sans MS\"><div style=\"text-align: justify\">While VGG16 achieved impressive results, it can be computationally expensive to train and use due to its depth. Newer architectures, often inspired by VGG16, balance performance with efficiency.</font>"
      ],
      "metadata": {
        "id": "KCJHyhw1ZlWp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"Brown\" size=+2 face=\"Comic Sans MS\"><div style=\"text-align: justify\">VGG16, although not the latest architecture, remains a valuable tool in computer vision for its foundational role and capability to be adapted for various tasks.</font>"
      ],
      "metadata": {
        "id": "60SowQwbZlWp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import cv2\n",
        "from cv2 import resize\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "from sklearn.metrics import confusion_matrix , accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T07:46:45.827544Z",
          "iopub.execute_input": "2024-04-15T07:46:45.828309Z",
          "iopub.status.idle": "2024-04-15T07:46:50.249465Z",
          "shell.execute_reply.started": "2024-04-15T07:46:45.828279Z",
          "shell.execute_reply": "2024-04-15T07:46:50.248648Z"
        },
        "trusted": true,
        "id": "ZHGr7bneZlWp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"Blue\" size=+3 face=\"Consolas\"><div style=\"text-align: justify\">Phasor measurement units (PMUs):</font>"
      ],
      "metadata": {
        "id": "BdVrlMq0ZlWq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"Brown\" size=+2 face=\"Comic Sans MS\"><div style=\"text-align: justify\">Wide area monitoring systems (WAMPC) play a crucial role in ensuring the smooth operation of smart grids. They help control centers maintain a resilient, efficient, and secure transmission system. The growing number of phasor measurement units (PMUs) in these systems has opened doors for innovative applications that aid decision-making in control centers.</font>\n",
        ""
      ],
      "metadata": {
        "id": "Qg2gm45pZlWq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"Brown\" size=+2 face=\"Comic Sans MS\"><div style=\"text-align: justify\">Machine learning (ML) is now a viable option for decision support systems, thanks to the abundance of high-resolution, wide-area PMU data. We propose a deep neural network (DNN) based system for supervisory protection and event diagnosis. This system has shown highly accurate results.</font>"
      ],
      "metadata": {
        "id": "CSEae3fuZlWq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<center><img src=\"https://library.e.abb.com/public/b0897d7de162495dc1256e37003ec533/1500x980_PSGuard_overviewi.jpg\"\n",
        "     width=\"50%\"\n",
        "     height=\"100%\" />"
      ],
      "metadata": {
        "id": "Luf7q66_ZlWq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"Blue\" size=+3 face=\"Consolas\"><div style=\"text-align: justify\">Phasor measurement units (PMUs) Data collection:</font>"
      ],
      "metadata": {
        "id": "M8VKwLvnZlWq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"Brown\" size=+2 face=\"Comic Sans MS\"><div style=\"text-align: justify\">This collection of images captures PMU data, similar to what's described in the reference paper. Each image represents a specific event that occurred in the power grid. The images are 300 pixels wide, 20 pixels tall, and have 3 color channels.</font>"
      ],
      "metadata": {
        "id": "6gZIuSxEZlWq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"Brown\" size=+2 face=\"Comic Sans MS\"><div style=\"text-align: justify\">Think of each image as a snapshot in time. It shows the voltage and frequency readings from 10 different PMUs over a 5-second period. To create these images, we took data from half a second before the event (like a premonition!) and 4.5 seconds afterward. The voltage and frequency data are from 10 PMUs, which are like sensors that monitor the health of the grid. We use color to represent these measurements, with each color channel showing a different aspect of the data.</font>"
      ],
      "metadata": {
        "id": "sllGSv7DZlWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Create Files_Name\n",
        "image_data='/kaggle/input/smart-grid-phasor-measurement-unit-faulty-data/IMG_PMU_DATA_NT_VF_001'\n",
        "pd.DataFrame(os.listdir(image_data),columns=['Files_Name'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T07:46:50.251156Z",
          "iopub.execute_input": "2024-04-15T07:46:50.251688Z",
          "iopub.status.idle": "2024-04-15T07:46:50.304802Z",
          "shell.execute_reply.started": "2024-04-15T07:46:50.251662Z",
          "shell.execute_reply": "2024-04-15T07:46:50.303897Z"
        },
        "trusted": true,
        "id": "_DaX7nhxZlWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_height = 244\n",
        "img_width = 244\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  '/kaggle/input/smart-grid-phasor-measurement-unit-faulty-data/IMG_PMU_DATA_NT_VF_001',\n",
        "  validation_split=0.2,\n",
        "  subset='training',\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=32,\n",
        "  seed=42,\n",
        "  shuffle=True)\n",
        "\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
        "  '/kaggle/input/smart-grid-phasor-measurement-unit-faulty-data/IMG_PMU_DATA_NT_VF_001',\n",
        "  validation_split=0.2,\n",
        "  subset='validation',\n",
        "  image_size=(img_height, img_width),\n",
        "  batch_size=32,\n",
        "  seed=42,\n",
        "  shuffle=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T07:46:50.306309Z",
          "iopub.execute_input": "2024-04-15T07:46:50.306693Z",
          "iopub.status.idle": "2024-04-15T07:46:52.864121Z",
          "shell.execute_reply.started": "2024-04-15T07:46:50.306663Z",
          "shell.execute_reply": "2024-04-15T07:46:52.863377Z"
        },
        "trusted": true,
        "id": "OqUAwqftZlWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_ds.class_names\n",
        "print(class_names)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T07:46:52.865164Z",
          "iopub.execute_input": "2024-04-15T07:46:52.865437Z",
          "iopub.status.idle": "2024-04-15T07:46:52.87045Z",
          "shell.execute_reply.started": "2024-04-15T07:46:52.865409Z",
          "shell.execute_reply": "2024-04-15T07:46:52.86951Z"
        },
        "trusted": true,
        "id": "k9-Li4lfZlWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"Blue\" size=+3 face=\"Consolas\"><div style=\"text-align: justify\">Phasor measurement units (PMUs) Description</font>"
      ],
      "metadata": {
        "id": "Hcx5FdGDZlWq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"Brown\" size=+2 face=\"Comic Sans MS\"><div style=\"text-align: justify\">DB_FLT: This folder contains 344 images representing faults in the power grid, like short circuits.</font>"
      ],
      "metadata": {
        "id": "InNDuHSyZlWq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"Brown\" size=+2 face=\"Comic Sans MS\"><div style=\"text-align: justify\">DB_GNL: This folder contains 140 images representing a loss of generation, where a power plant goes offline.</font>"
      ],
      "metadata": {
        "id": "9-yqIH5aZlWq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"Brown\" size=+2 face=\"Comic Sans MS\"><div style=\"text-align: justify\">DB_SMS: This folder contains 21 images representing synchronous motor switching events, which are changes in how a large motor is connected to the grid.</font>"
      ],
      "metadata": {
        "id": "h7w8OJpyZlWq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(20, 15))\n",
        "for images, labels in train_ds.take(1):\n",
        "    for i in range(25):\n",
        "        ax = plt.subplot(5, 5, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(class_names[labels[i]])\n",
        "        plt.axis(\"off\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T07:46:52.873288Z",
          "iopub.execute_input": "2024-04-15T07:46:52.87358Z",
          "iopub.status.idle": "2024-04-15T07:46:56.136115Z",
          "shell.execute_reply.started": "2024-04-15T07:46:52.873556Z",
          "shell.execute_reply": "2024-04-15T07:46:56.134926Z"
        },
        "trusted": true,
        "id": "hPrp190NZlWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model = tf.keras.applications.VGG16(\n",
        "    include_top=False,\n",
        "    weights='imagenet',\n",
        "    input_shape=(img_height, img_width, 3)\n",
        ")\n",
        "base_model.trainable = False"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T07:46:56.137439Z",
          "iopub.execute_input": "2024-04-15T07:46:56.137758Z",
          "iopub.status.idle": "2024-04-15T07:46:56.468107Z",
          "shell.execute_reply.started": "2024-04-15T07:46:56.137731Z",
          "shell.execute_reply": "2024-04-15T07:46:56.467248Z"
        },
        "trusted": true,
        "id": "k9YeCwnLZlWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input(shape=(img_height, img_width, 3))\n",
        "x = tf.keras.applications.vgg16.preprocess_input(inputs)\n",
        "x = base_model(x, training=False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.3)(x)\n",
        "outputs = tf.keras.layers.Dense(90)(x)\n",
        "model = tf.keras.Model(inputs, outputs)\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T07:46:56.469189Z",
          "iopub.execute_input": "2024-04-15T07:46:56.469458Z",
          "iopub.status.idle": "2024-04-15T07:46:56.528244Z",
          "shell.execute_reply.started": "2024-04-15T07:46:56.469435Z",
          "shell.execute_reply": "2024-04-15T07:46:56.527318Z"
        },
        "trusted": true,
        "id": "FQF4F7T-ZlWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf  # Assuming you're using TensorFlow\n",
        "\n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "# Assuming you have your Keras model defined as 'model'\n",
        "\n",
        "plot_model(model, to_file='cnn_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T07:46:56.529539Z",
          "iopub.execute_input": "2024-04-15T07:46:56.529911Z",
          "iopub.status.idle": "2024-04-15T07:46:57.059556Z",
          "shell.execute_reply.started": "2024-04-15T07:46:56.529881Z",
          "shell.execute_reply": "2024-04-15T07:46:57.058743Z"
        },
        "trusted": true,
        "id": "jbi_HVrbZlWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T07:46:57.061328Z",
          "iopub.execute_input": "2024-04-15T07:46:57.061654Z",
          "iopub.status.idle": "2024-04-15T07:46:57.077488Z",
          "shell.execute_reply.started": "2024-04-15T07:46:57.061626Z",
          "shell.execute_reply": "2024-04-15T07:46:57.076398Z"
        },
        "trusted": true,
        "id": "S3ZlOswrZlWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 20\n",
        "model.fit(train_ds, validation_data=val_ds, epochs=epoch,\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor=\"val_loss\",\n",
        "            min_delta=1e-2,\n",
        "            patience=3,\n",
        "            verbose=1,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T07:46:57.079197Z",
          "iopub.execute_input": "2024-04-15T07:46:57.079497Z",
          "iopub.status.idle": "2024-04-15T07:48:52.003731Z",
          "shell.execute_reply.started": "2024-04-15T07:46:57.079474Z",
          "shell.execute_reply": "2024-04-15T07:48:52.002772Z"
        },
        "trusted": true,
        "id": "zU68l_7lZlWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T07:48:52.005177Z",
          "iopub.execute_input": "2024-04-15T07:48:52.005491Z",
          "iopub.status.idle": "2024-04-15T07:48:52.016209Z",
          "shell.execute_reply.started": "2024-04-15T07:48:52.005463Z",
          "shell.execute_reply": "2024-04-15T07:48:52.015486Z"
        },
        "trusted": true,
        "id": "Y9jdzagLZlWr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fine tuning\n",
        "base_model.trainable = True\n",
        "for layer in base_model.layers[:14]:\n",
        "    layer.trainable = False\n",
        "model.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T07:48:52.017497Z",
          "iopub.execute_input": "2024-04-15T07:48:52.01785Z",
          "iopub.status.idle": "2024-04-15T07:48:52.052247Z",
          "shell.execute_reply.started": "2024-04-15T07:48:52.017826Z",
          "shell.execute_reply": "2024-04-15T07:48:52.051221Z"
        },
        "trusted": true,
        "id": "rE-lQ0_uZlWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(0.0001),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T07:48:52.053489Z",
          "iopub.execute_input": "2024-04-15T07:48:52.053829Z",
          "iopub.status.idle": "2024-04-15T07:48:52.063159Z",
          "shell.execute_reply.started": "2024-04-15T07:48:52.053804Z",
          "shell.execute_reply": "2024-04-15T07:48:52.062277Z"
        },
        "trusted": true,
        "id": "XhmOZFZ3ZlWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 20\n",
        "history = model.fit(train_ds, validation_data=val_ds, epochs=epoch,\n",
        "    callbacks = [\n",
        "        tf.keras.callbacks.EarlyStopping(\n",
        "            monitor=\"val_loss\",\n",
        "            min_delta=1e-2,\n",
        "            patience=3,\n",
        "            verbose=1,\n",
        "        )\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T07:48:52.066596Z",
          "iopub.execute_input": "2024-04-15T07:48:52.066918Z",
          "iopub.status.idle": "2024-04-15T07:49:20.774068Z",
          "shell.execute_reply.started": "2024-04-15T07:48:52.066892Z",
          "shell.execute_reply": "2024-04-15T07:49:20.772937Z"
        },
        "trusted": true,
        "id": "pfDUbRVbZlWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist_=pd.DataFrame(history.history)\n",
        "hist_"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T07:49:20.775481Z",
          "iopub.execute_input": "2024-04-15T07:49:20.775858Z",
          "iopub.status.idle": "2024-04-15T07:49:20.791021Z",
          "shell.execute_reply.started": "2024-04-15T07:49:20.775827Z",
          "shell.execute_reply": "2024-04-15T07:49:20.789786Z"
        },
        "trusted": true,
        "id": "U5dQljJ0ZlWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_ac = history.history['accuracy']\n",
        "get_los = history.history['loss']\n",
        "val_acc = history.history['val_accuracy']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(get_ac))\n",
        "\n",
        "# Create a figure with 3 subplots arranged vertically\n",
        "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(10, 15))  # Adjust figsize as needed\n",
        "\n",
        "# Plot training accuracy and loss\n",
        "ax1.plot(epochs, get_ac, 'g', label='Accuracy of Training Data')\n",
        "ax1.plot(epochs, get_los, 'r', label='Loss of Training Data')\n",
        "ax1.set_title('Training Data Accuracy and Loss')\n",
        "ax1.legend(loc=0)\n",
        "\n",
        "# Plot training and validation accuracy\n",
        "ax2.plot(epochs, get_ac, 'g', label='Accuracy of Training Data')\n",
        "ax2.plot(epochs, val_acc, 'r', label='Accuracy of Validation Data')\n",
        "ax2.set_title('Training and Validation Accuracy')\n",
        "ax2.legend(loc=0)\n",
        "\n",
        "# Plot training and validation loss\n",
        "ax3.plot(epochs, get_los, 'g', label='Loss of Training Data')\n",
        "ax3.plot(epochs, val_loss, 'r', label='Loss of Validation Data')\n",
        "ax3.set_title('Training and Validation Loss')\n",
        "ax3.legend(loc=0)\n",
        "\n",
        "# Adjust spacing between subplots (optional)\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T07:49:20.792379Z",
          "iopub.execute_input": "2024-04-15T07:49:20.793001Z",
          "iopub.status.idle": "2024-04-15T07:49:21.750874Z",
          "shell.execute_reply.started": "2024-04-15T07:49:20.792965Z",
          "shell.execute_reply": "2024-04-15T07:49:21.749802Z"
        },
        "trusted": true,
        "id": "M9o81MwrZlWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_val,y_val,y_pred=[],[],[]\n",
        "for images, labels in val_ds:\n",
        "    y_val.extend(labels.numpy())\n",
        "    X_val.extend(images.numpy())\n",
        "predictions=model.predict(np.array(X_val))\n",
        "for i in predictions:\n",
        "    y_pred.append(np.argmax(i))\n",
        "df=pd.DataFrame()\n",
        "df['Actual'],df['Prediction']=y_val,y_pred\n",
        "df"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T07:49:21.752495Z",
          "iopub.execute_input": "2024-04-15T07:49:21.75289Z",
          "iopub.status.idle": "2024-04-15T07:49:23.850937Z",
          "shell.execute_reply.started": "2024-04-15T07:49:21.752858Z",
          "shell.execute_reply": "2024-04-15T07:49:23.849804Z"
        },
        "trusted": true,
        "id": "AF98CEx9ZlWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax= plt.subplot()\n",
        "CM = confusion_matrix(y_val,y_pred)\n",
        "sns.heatmap(CM, annot=True, fmt='g', ax=ax,cbar=False,cmap='RdBu')\n",
        "ax.set_xlabel('Predicted labels')\n",
        "ax.set_ylabel('True labels')\n",
        "ax.set_title('Confusion Matrix')\n",
        "plt.show()\n",
        "CM"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T07:49:23.852379Z",
          "iopub.execute_input": "2024-04-15T07:49:23.852838Z",
          "iopub.status.idle": "2024-04-15T07:49:24.071411Z",
          "shell.execute_reply.started": "2024-04-15T07:49:23.852799Z",
          "shell.execute_reply": "2024-04-15T07:49:24.070257Z"
        },
        "trusted": true,
        "id": "9Q9hJIWVZlWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Acc = accuracy_score(y_val,y_pred)\n",
        "print(\"accuracy is: {0:.2f}%\".format(Acc * 100))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T07:49:24.072535Z",
          "iopub.execute_input": "2024-04-15T07:49:24.07287Z",
          "iopub.status.idle": "2024-04-15T07:49:24.079094Z",
          "shell.execute_reply.started": "2024-04-15T07:49:24.072844Z",
          "shell.execute_reply": "2024-04-15T07:49:24.078137Z"
        },
        "trusted": true,
        "id": "DafbNbloZlWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Assuming you have already evaluated the model using model.evaluate(val_ds)\n",
        "# and obtained the loss and accuracy values\n",
        "\n",
        "loss, accuracy = model.evaluate(val_ds)  # Assuming you have this line\n",
        "\n",
        "# Display accuracy percentage\n",
        "print(\"Accuracy:\", accuracy * 100, \"%\")  # Convert accuracy to percentage\n",
        "\n",
        "# Get a batch of images and labels from the validation dataset\n",
        "images, labels = next(iter(val_ds))  # This retrieves one batch\n",
        "\n",
        "# Create a 4x4 grid of subplots\n",
        "plt.figure(figsize=(20, 20))  # Adjust figure size as needed\n",
        "\n",
        "for i in range(16):\n",
        "    ax = plt.subplot(4, 4, i + 1)\n",
        "\n",
        "    # Display the image\n",
        "    plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "\n",
        "    # Make predictions on the current image\n",
        "    predictions = model.predict(tf.expand_dims(images[i], 0))\n",
        "    score = tf.nn.softmax(predictions[0])\n",
        "\n",
        "    # Determine the predicted class index and label\n",
        "    predicted_class_idx = np.argmax(score)\n",
        "    predicted_class_label = class_names[predicted_class_idx]\n",
        "\n",
        "    # Determine the actual class label\n",
        "    actual_class_label = class_names[labels[i]]\n",
        "\n",
        "    # Set title and labels with accuracy percentage\n",
        "    if actual_class_label == predicted_class_label:\n",
        "        color = 'green'\n",
        "        accuracy_text = f\"Correct ({actual_class_label})\"\n",
        "    else:\n",
        "        color = 'red'\n",
        "        accuracy_text = f\"Incorrect (Actual: {actual_class_label}, Predicted: {predicted_class_label})\"\n",
        "\n",
        "    # Convert score to NumPy array for rounding\n",
        "    score_np = score.numpy()  # Convert TensorFlow tensor to NumPy array\n",
        "    predicted_prob = round(score_np[predicted_class_idx] * 100, 2)  # Round prediction probability\n",
        "\n",
        "    plt.title(f\"{accuracy_text}\\nProb: {predicted_prob}%\", color=color, fontsize=15)\n",
        "    plt.gca().axes.yaxis.set_ticklabels([])\n",
        "    plt.gca().axes.xaxis.set_ticklabels([])\n",
        "\n",
        "plt.tight_layout()  # Adjust spacing between subplots\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-15T07:51:27.173922Z",
          "iopub.execute_input": "2024-04-15T07:51:27.175078Z",
          "iopub.status.idle": "2024-04-15T07:51:32.561335Z",
          "shell.execute_reply.started": "2024-04-15T07:51:27.175041Z",
          "shell.execute_reply": "2024-04-15T07:51:32.559389Z"
        },
        "trusted": true,
        "id": "2fe_A00-ZlWt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"Blue\" size=+3 face=\"Consolas\"><div style=\"text-align: justify\">Conclusion: </font>"
      ],
      "metadata": {
        "id": "ZpIBd7gOZlWt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"Brown\" size=+2 face=\"Comic Sans MS\"><div style=\"text-align: justify\">Imagine monitoring a complex power grid with phasor measurement units (PMUs) constantly streaming data at high speeds. Analyzing this vast amount of data quickly and accurately to identify faults is a significant challenge for grid operators. Traditional methods can be time-consuming and prone to errors.</font>\n"
      ],
      "metadata": {
        "id": "ki-494I8ZlWt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color=\"Brown\" size=+2 face=\"Comic Sans MS\"><div style=\"text-align: justify\">That's where our VGG16-based deep learning system comes in! It acts like a powerful assistant, sifting through the PMU data with exceptional accuracy (98.75%). This translates to a system that can effectively categorize different grid events, including faults, loss of generation, and synchronous motor switching events â€“ all at high speed.</font>"
      ],
      "metadata": {
        "id": "k5Qg59zAZlWt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "<font color=\"Brown\" size=+2 face=\"Comic Sans MS\"><div style=\"text-align: justify\">Faster Fault Detection: By quickly identifying faults, the system enables operators to respond promptly, minimizing damage and downtime.Improved Decision-Making: With accurate event classification, operators can make more informed decisions about grid management and resource allocation. Enhanced Grid Resilience: Early detection and response to events contribute to a more resilient grid, reducing the risk of widespread outages.\n",
        "In essence, VGG16 empowers us to unlock the true potential of PMU data, leading to a smarter, more reliable, and efficient power grid for everyone.</font>"
      ],
      "metadata": {
        "id": "cILNzlzqZlWt"
      }
    }
  ]
}